@inproceedings{wespeaker,
  title={Wespeaker: A research and production oriented speaker embedding learning toolkit},
  author={Wang, Hongji and Liang, Chengdong and Wang, Shuai and Chen, Zhengyang and Zhang, Binbin and Xiang, Xu and Deng, Yanlei and Qian, Yanmin},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@misc{transformer,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{shazeer2017outrageously,
      title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer}, 
      author={Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},
      year={2017},
      eprint={1701.06538},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wav2vec2,
      title={wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations}, 
      author={Alexei Baevski and Henry Zhou and Abdelrahman Mohamed and Michael Auli},
      year={2020},
      eprint={2006.11477},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wav2vec,
      title={wav2vec: Unsupervised Pre-training for Speech Recognition}, 
      author={Steffen Schneider and Alexei Baevski and Ronan Collobert and Michael Auli},
      year={2019},
      eprint={1904.05862},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{whisper,
      title={Robust Speech Recognition via Large-Scale Weak Supervision}, 
      author={Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey and Ilya Sutskever},
      year={2022},
      eprint={2212.04356},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@INPROCEEDINGS{librispeech,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Librispeech: An ASR corpus based on public domain audio books}, 
  year={2015},
  volume={},
  number={},
  pages={5206-5210},
  keywords={Resource description framework;Genomics;Bioinformatics;Blogs;Information services;Electronic publishing;Speech Recognition;Corpus;LibriVox},
  doi={10.1109/ICASSP.2015.7178964}
}

@article{timit,
author = {Garofolo, J. and Lamel, Lori and Fisher, W. and Fiscus, Jonathan and Pallett, D. and Dahlgren, N. and Zue, V.},
year = {1992},
month = {11},
pages = {},
title = {TIMIT Acoustic-phonetic Continuous Speech Corpus},
journal = {Linguistic Data Consortium}
}

@misc{hubert,
      title={HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units}, 
      author={Wei-Ning Hsu and Benjamin Bolte and Yao-Hung Hubert Tsai and Kushal Lakhotia and Ruslan Salakhutdinov and Abdelrahman Mohamed},
      year={2021},
      eprint={2106.07447},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{childspeech,
      title={Sparsely Shared LoRA on Whisper for Child Speech Recognition}, 
      author={Wei Liu and Ying Qin and Zhiyuan Peng and Tan Lee},
      year={2024},
      eprint={2309.11756},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@misc{speakeradaptation,
      title={A Unified Speaker Adaptation Approach for ASR}, 
      author={Yingzhu Zhao and Chongjia Ni and Cheung-Chi Leung and Shafiq Joty and Eng Siong Chng and Bin Ma},
      year={2021},
      eprint={2110.08545},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@misc{loraonlm,
      title={Investigating Training Strategies and Model Robustness of Low-Rank Adaptation for Language Modeling in Speech Recognition}, 
      author={Yu Yu and Chao-Han Huck Yang and Tuan Dinh and Sungho Ryu and Jari Kolehmainen and Roger Ren and Denis Filimonov and Prashanth G. Shivakumar and Ankur Gandhe and Ariya Rastow and Jia Xu and Ivan Bulyko and Andreas Stolcke},
      year={2024},
      eprint={2401.10447},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{huggingface,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      eprint={1910.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{superb,
      title={SUPERB: Speech processing Universal PERformance Benchmark}, 
      author={Shu-wen Yang and Po-Han Chi and Yung-Sung Chuang and Cheng-I Jeff Lai and Kushal Lakhotia and Yist Y. Lin and Andy T. Liu and Jiatong Shi and Xuankai Chang and Guan-Ting Lin and Tzu-Hsien Huang and Wei-Cheng Tseng and Ko-tik Lee and Da-Rong Liu and Zili Huang and Shuyan Dong and Shang-Wen Li and Shinji Watanabe and Abdelrahman Mohamed and Hung-yi Lee},
      year={2021},
      eprint={2105.01051},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{conformerxll,
      title={Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition}, 
      author={Yu Zhang and James Qin and Daniel S. Park and Wei Han and Chung-Cheng Chiu and Ruoming Pang and Quoc V. Le and Yonghui Wu},
      year={2022},
      eprint={2010.10504},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@misc{contextnet,
      title={ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context}, 
      author={Wei Han and Zhengdong Zhang and Yu Zhang and Jiahui Yu and Chung-Cheng Chiu and James Qin and Anmol Gulati and Ruoming Pang and Yonghui Wu},
      year={2020},
      eprint={2005.03191},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@misc{npc,
      title={Non-Autoregressive Predictive Coding for Learning Speech Representations from Local Dependencies}, 
      author={Alexander H. Liu and Yu-An Chung and James Glass},
      year={2020},
      eprint={2011.00406},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@INPROCEEDINGS{comparative,
  author={Pasad, Ankita and Shi, Bowen and Livescu, Karen},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Comparative Layer-Wise Analysis of Self-Supervised Speech Models}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  keywords={Representation learning;Analytical models;Navigation;Speech recognition;Syntactics;Signal processing;Market research;Self-supervised pre-training;model analysis;speech representation learning},
  doi={10.1109/ICASSP49357.2023.10096149}
}

@INPROCEEDINGS{layerwise,
  author={Pasad, Ankita and Chou, Ju-Chieh and Livescu, Karen},
  booktitle={2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={Layer-Wise Analysis of a Self-Supervised Speech Representation Model}, 
  year={2021},
  volume={},
  number={},
  pages={914-921},
  keywords={Training;Representation learning;Analytical models;Protocols;Semantics;Linguistics;Acoustics;Self-supervised pre-training;representation analysis;speech representation learning},
  doi={10.1109/ASRU51503.2021.9688093}
}

@inproceedings{onlinesaasr,
  author={Chih Chi Hu and Bing Liu and John Shen and Ian Lane},
  title={{Online Incremental Learning for Speaker-Adaptive Language Models}},
  year=2018,
  booktitle={Proc. Interspeech 2018},
  pages={3363--3367},
  doi={10.21437/Interspeech.2018-2259}
}

@inproceedings{speakeradaptationlstm,
  title={On speaker adaptation of long short-term memory recurrent neural networks},
  author={Yajie Miao and Florian Metze},
  booktitle={Interspeech},
  year={2015},
  url={https://api.semanticscholar.org/CorpusID:9348175}
}

@misc{choi2021neural,
      title={Neural Analysis and Synthesis: Reconstructing Speech from Self-Supervised Representations}, 
      author={Hyeong-Seok Choi and Juheon Lee and Wansoo Kim and Jie Hwan Lee and Hoon Heo and Kyogu Lee},
      year={2021},
      eprint={2110.14513},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}


@InProceedings{contentvec,
  title = 	 {{C}ontent{V}ec: An Improved Self-Supervised Speech Representation by Disentangling Speakers},
  author =       {Qian, Kaizhi and Zhang, Yang and Gao, Heting and Ni, Junrui and Lai, Cheng-I and Cox, David and Hasegawa-Johnson, Mark and Chang, Shiyu},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {18003--18017},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/qian22b/qian22b.pdf},
  url = 	 {https://proceedings.mlr.press/v162/qian22b.html},
  abstract = 	 {Self-supervised learning in speech involves training a speech representation network on a large-scale unannotated speech corpus, and then applying the learned representations to downstream tasks. Since the majority of the downstream tasks of SSL learning in speech largely focus on the content information in speech, the most desirable speech representations should be able to disentangle unwanted variations, such as speaker variations, from the content. However, disentangling speakers is very challenging, because removing the speaker information could easily result in a loss of content as well, and the damage of the latter usually far outweighs the benefit of the former. In this paper, we propose a new SSL method that can achieve speaker disentanglement without severe loss of content. Our approach is adapted from the HuBERT framework, and incorporates disentangling mechanisms to regularize both the teacher labels and the learned representations. We evaluate the benefit of speaker disentanglement on a set of content-related downstream tasks, and observe a consistent and notable performance advantage of our speaker-disentangled representations.}
}

@misc{spin,
      title={Self-supervised Fine-tuning for Improved Content Representations by Speaker-invariant Clustering}, 
      author={Heng-Jui Chang and Alexander H. Liu and James Glass},
      year={2023},
      eprint={2305.11072},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lora,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
