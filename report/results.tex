\section{Results}

\begin{table}[htbp]
  \centering
  \begin{tabular}{lc}
    \toprule
    \textbf{Model} &WER \\
    \midrule
    Whisper Large V2 \cite{whisperv2} &2.7 \\
    Wav2Vec 2.0 \cite{wav2vec2} &2.3??? \\
    \midrule
    AttentionLoRA(K=4) &TODO \\
    ClusterModel(K=4) &TODO \\
    ClusterModel(K=8) &TODO \\
    \bottomrule
  \end{tabular}
  \caption{Word Error Rate (WER) of various models on the train.clean partition of LibriSpeech. Lower values indicate better performance.}
  \label{tab:video_descriptor_comparison}
\end{table}

Results are shown in Table \ref{tab:video_descriptor_comparison}.

\subsection{Per-Speaker Performance}

Since the proposed AttentionLoRA and ClusterModel models are designed to be speaker-dependent,
we provide a brief analysis on per-speaker performance to better understand these systems.

Figure \ref{TODO} shows the change in WER by speaker, between the original base wav2vec 2.0 model and the ClusterModel(K=4) model.
